{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adriano.Palmieri\\AppData\\Local\\Continuum\\anaconda3\\envs\\qiskit\\lib\\site-packages\\qutip\\__init__.py:59: UserWarning: Old version of Cython detected: needed 0.29.20, got 0.29.15.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import *\n",
    "import functools as fu\n",
    "from numpy import kron\n",
    "from numpy.linalg import cholesky, eig\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from qiskit.quantum_info import random_density_matrix\n",
    "from qutip import rand_dm_hs, Qobj, fidelity\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leading dimension to set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of particles\n",
    "d = 4\n",
    "#local dimension (qubit, qutrit...)\n",
    "local_dim = 2 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1) depolarization and dephasing channel\n",
    "\n",
    "here we provide a local and a global depolarizing channel, to introduce an extra physical channel. This files can be used in step 3 during the data generatoin and linear inversion pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_depolarizing_channel(qubits_number, density_matrix, probability):\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tNOTE: this function must be used inside a for loop to get to apply each pauli's operator for each state\n",
    "\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tpX = np.array([[0.,1.], [1.,0.]]) # X Pauli matrix\n",
    "\t\tpY = np.array([[0.,-1.j], [1.j, 0.]]) # Y Pauli matrix\n",
    "\t\tpZ = np.array([[1., 0.], [0.,-1.]]) # Z Pauli matrix\n",
    "\t\tpI = np.array([[1.,0.], [0.,1.]])\n",
    "\n",
    "\t\tfor i in range(qubits_number):\n",
    "\t\t\t\n",
    "\t\t\toperator_string_x = list(repeat(pI,qubits_number))\n",
    "\t\t\toperator_string_y = list(repeat(pI,qubits_number))\n",
    "\t\t\toperator_string_z = list(repeat(pI,qubits_number))\n",
    "\t\t\t\n",
    "\n",
    "\t\t\toperator_string_x[i] = pX\n",
    "\t\t\toperator_string_y[i] = pY\n",
    "\t\t\toperator_string_z[i] = pZ\n",
    "\t\n",
    "\t\t\tX = fu.reduce(np.kron,operator_string_x)\n",
    "\t\t\tY = fu.reduce(np.kron,operator_string_y)\n",
    "\t\t\tZ = fu.reduce(np.kron,operator_string_z)\n",
    "\t\t\n",
    "\t\t\tnew_density_matrix = (1-probability)*density_matrix \n",
    "\t\t\t\n",
    "\t\t\tnew_density_matrix = new_density_matrix + (probability/3)*X.dot(density_matrix).dot(X)\n",
    "\t\t\t#print(new_density_matrix.shape)\n",
    "\t\t\tnew_density_matrix = new_density_matrix + (probability/3)*Y.dot(density_matrix).dot(Y)\n",
    "\n",
    "\t\t\tnew_density_matrix = new_density_matrix + (probability/3)*Z.dot(density_matrix).dot(Z)\n",
    "\t\t\t\t\n",
    "\t\treturn new_density_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_depo_channel(dm,p):\n",
    "    \n",
    "    dim = dm.shape[0]\n",
    "    I = np.eye(dim,dim)\n",
    "    \n",
    "    return (1-p)*dm + (p/(dim))*I\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support functions:\n",
    "1. the vectorization of the Cholesky matrices $vec(C_{ij})$.\n",
    "2. positive semidefinite brute-force approximation of non physical matrices $\\rho_{LI}$(eigenvaluescheck, PureEigenvaluesCheck)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vectorization_new(rho):\n",
    "\t\n",
    "\tdim = rho.shape[0]\n",
    "\t#chol = np.linalg.cholesky(rho)\n",
    "\tchol = \ttorch.linalg.cholesky(torch.complex(torch.Tensor(rho.real),torch.Tensor(rho.imag)))\n",
    "\n",
    "\tdiag = np.diag(chol).real.tolist()\n",
    "\n",
    "\tlower_t_indeces = np.tril_indices_from(chol,k=-1)\n",
    "\n",
    "\treals = list(chol[lower_t_indeces].real.flatten())\n",
    "\timags = list(chol[lower_t_indeces].imag.flatten())\n",
    "\n",
    "\treturn np.array(diag+reals+imags, dtype=np.float64)\n",
    "\n",
    "\n",
    "def from_mpc_tonumpy(colored_rho):\n",
    "\n",
    "\t\"\"\"\n",
    "\tinput: a density matrix, mpc type\n",
    "\toutput: nd.array of the same density matrix recasted in complex128 type\n",
    "\t\"\"\"\n",
    "\tplaceholder = np.zeros((colored_rho.shape[0],colored_rho.shape[1]),dtype=complex)\n",
    "\tfor r in range(colored_rho.shape[0]):\n",
    "\t\tfor c in range(colored_rho.shape[1]):\n",
    "\t\t\ta =np.double(mp.nstr(mp.re(colored_rho[r][c])))\n",
    "\t\t\tb = np.double(mp.nstr(mp.im(colored_rho[r][c])))\n",
    "\t\t\tbuilt = complex(a,b)\n",
    "\t\t\tplaceholder[r][c] = built\n",
    "\treturn placeholder\n",
    "\n",
    "def eigenvaluesCheck(dm):\n",
    "\n",
    "\teis, eigvecs = eig(dm)\n",
    "\n",
    "\teis[eis.real <0 ] = 0.0001\n",
    "\teis = [ el.real for el in eis]\n",
    "\teis = np.array(eis)\n",
    "\n",
    "\tcleanRho = eigvecs@ np.diag(eis) @ eigvecs.T.conj()\n",
    "\n",
    "\treturn cleanRho/np.trace(cleanRho)\n",
    "\t\n",
    "def PureEigenvaluesCheck(dm):\n",
    "\n",
    "\teis, eigvecs = eig(dm)\n",
    "\n",
    "\teis[eis.real.round(2) < 0.99 ] = 0.0001\n",
    "\teis = [ el.real for el in eis]\n",
    "\teis = np.array(eis)\n",
    "\n",
    "\tcleanRho = eigvecs@ np.diag(eis) @ eigvecs.T.conj()\n",
    "\n",
    "\treturn cleanRho/np.trace(cleanRho)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Uploading the n qubits basis\n",
    "\n",
    "here we upload the informationally complete set of basis, one for generate the Bhorn values $p_i= Tr(\\rho\\pi_i)$, and the corrispondenting dual $\\tilde{\\pi}_i$ to reconstruct our density matrix from experimental values $\\rho_{back} =\\sum_i  f_i\\tilde{\\pi}_i $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_basis = np.load(\"basis-generation/4-qubits/4qubitsPauli.npy \", allow_pickle=True)\n",
    "reconstruction_basis = np.load(\"basis-generation/4-qubits/4qubitsPauliReconstruction.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 16, 16)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_basis.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Random states generation, pre-processing, training dataset preparation.\n",
    "\n",
    "Here we orderly do:\n",
    "\n",
    "1. generate random matrices\n",
    "2. calculate Born values\n",
    "3. approximate with fine statistics, fixing the parameter \"trials\" (for SICS), or normalizing the Gaussian noise (for Pauli)\n",
    "4. using linear inversion to reconstruct the density matrix, and approximate it to the close positive definite approximation thereof, killing the negative eigenvalues\n",
    "5. vectorize the original matrix and the new, experimental one. This is our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "totarr =[]\n",
    "hs = []\n",
    "tot =1\n",
    "i = 0\n",
    "\n",
    "trials = 1000\n",
    "\n",
    "folder = '../multinomialData/'\n",
    "filename = 'Haar4qubitsTrials'+str(trials)+'Sic.npy'\n",
    "\n",
    "if not os.path.isdir(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "def HSdist(A,B):\n",
    "    return np.trace((A-B)@(A-B)).real\n",
    "  \n",
    "hsm = []\n",
    "while True:\n",
    "\n",
    "\t#rho_start0 = np.array(rand_dm_hs(local_dim**d).full())\n",
    "\t#PURE STATES\n",
    "\trho_startA = np.array(random_density_matrix(local_dim**d,rank=1, method = \"Hilbert-Schmidt\").data)\n",
    "\t#rho_start0 = global_depo_channel(rho_start0,0.1)\n",
    "\ts_borns =  np.array([ np.trace(rho_startA @ base).real for base in general_basis])\n",
    "\t\n",
    "\t#MULTINOMIAL. This is for Guillem,PRA alike tests!!\n",
    "\ts_borns_approx = np.random.multinomial(trials, s_borns)/trials\n",
    "\t\n",
    "\t#reconstruct the approximation, first step of linear inversion\n",
    "\t\n",
    "\trback = sum([ np.round(reconstruction_basis[i],12)*s_borns_approx[i] for i in range(4**d) ])\n",
    "\t#brute force approximation upon LI\n",
    "\tcleanRho = eigenvaluesCheck(rback)\n",
    "\n",
    "\tchol_exp = [ vectorization_new(cleanRho)  ]\n",
    "\n",
    "\ttry:\n",
    "\t\t#use eigenvaluesCheck in case the states are not pure ones.\n",
    "\n",
    "\t\tchol_theoretic = vectorization_new(PureEigenvaluesCheck(rho_startA))\n",
    "\t\t#hsm.append(HSdist(rho_start0,rback))\n",
    "\t\ttotarr.append( np.concatenate((chol_exp, chol_theoretic), axis=None) )\n",
    "\n",
    "\t\t#LI metrics\n",
    "\t\t#totarr.append(fidelity(Qobj(cleanRho),Qobj(rho_startA)))\n",
    "\t\t#hs.append(HSdist(cleanRho,rho_start0 ))\n",
    "\t\ti+=1\n",
    "\t\t#print(np.trace(rho_start0@rho_start0))\n",
    "\texcept RuntimeError:\n",
    "\t\tpass\n",
    "\t\n",
    "\tif i == tot:\n",
    "\n",
    "\t\tnp.save(folder +filename,np.array(totarr))\n",
    "\t\tbreak\n",
    "\telse:\n",
    "\t\tpass\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAULI basis data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.stats import norm\n",
    "\n",
    "totarr =[]\n",
    "hs = []\n",
    "tot =1\n",
    "i = 0\n",
    "li = []\n",
    "\n",
    "trials = 1000\n",
    "\n",
    "normTrials = np.sqrt(trials/(local_dim**(d)))\n",
    "\n",
    "folder = '../multinomialData/'\n",
    "filename = 'Haar4qubitsTrials'+str(trials)+'PAULI.npy'\n",
    "\n",
    "if not os.path.isdir(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "def HSdist(A,B):\n",
    "    return np.trace((A-B)@(A-B)).real\n",
    "  \n",
    "hsm = []\n",
    "while True:\n",
    "\n",
    "\t#PURE STATES\n",
    "\trho_start0 = np.array(random_density_matrix(local_dim**d,rank=1, method = \"Hillbert_Schmidt\").data)\n",
    "\t#rho_start0 = global_depo_channel(rho_start0,0.1)\n",
    "\tborns =  np.array([ np.trace(rho_start0 @ base).real for base in general_basis])\n",
    "\n",
    "\t#OLD ONE\n",
    "\tsingleFreqVariance = norm.rvs(size = local_dim**(2*d))/8\n",
    "\t#\n",
    "\tborns_approx =  [ el1+el2 for el1,el2 in zip(borns,singleFreqVariance) ]  \n",
    "\n",
    "\t#reconstruct the approximation, first stage of linear inversion\n",
    "\trback = sum([ np.round(reconstruction_basis[i],12)*borns_approx[i] for i in range(4**d) ])\n",
    "\t\n",
    "\t#brute force approximation upon LI\n",
    "\tcleanRho = eigenvaluesCheck(rback)\n",
    "\n",
    "\tchol_exp = [ vectorization_new(cleanRho)  ]\n",
    "\n",
    "\ttry:\n",
    "\t\t#LI test\n",
    "\t\tli.append(fidelity(Qobj(cleanRho),Qobj(rho_start0)))\n",
    "\t\t#hs.append(HSdist(cleanRho,rho_start0 ))\n",
    "\n",
    "\t\t\n",
    "\t\tchol_theoretic = vectorization_new(PureEigenvaluesCheck(rho_start0))\n",
    "\t\ttotarr.append( np.concatenate((chol_exp, chol_theoretic), axis=None) )\n",
    "\t\ti+=1\n",
    "\t\t#print(i)\n",
    "\texcept RuntimeError:\n",
    "\t\tpass\n",
    "\t\n",
    "\tif i == tot:\n",
    "\n",
    "\t\t#np.save(folder +filename,np.array(totarr))\n",
    "\t\tbreak\n",
    "\telse:\n",
    "\t\tpass\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(li)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) OUT OF DISTRIBUTION\n",
    "\n",
    "here we generate different preparation of the target OAT state evolution (which consists of 100 time steps).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm = pd.read_pickle('outofdistribution100.pkl').to_numpy()\n",
    "\n",
    "type(rm[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.stats import norm\n",
    "\n",
    "totarr =[]\n",
    "tot = rm.shape[0]\n",
    "i = 0\n",
    "li2 = []\n",
    "#trials = 1000\n",
    "#normTrials = np.sqrt(trials/(local_dim**(d)))\n",
    "\n",
    "folder = '../articlePlotPaulibla/'\n",
    "#filename = 'sample11-100stepsPauli4qubitsTrials'+str(trials)+'OfD.npy'\n",
    "filename = 'sample20-100stepsSic4qubitsFid85OfD.npy'\n",
    "\n",
    "if not os.path.isdir(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "hsm = []\n",
    "while True:\n",
    "\n",
    "\tborns =  np.array([ np.trace(rm[i][0] @ base).real for base in general_basis])\n",
    "\n",
    "\t#borns_approx = np.random.multinomial(trials, borns)/trials\n",
    "\n",
    "\t#FOR PAULI\n",
    "\tsingleFreqVariance = norm.rvs(size = local_dim**(2*d))/18\n",
    "\tborns_approx =  [ el1+el2 for el1,el2 in zip(borns,singleFreqVariance) ]  \n",
    "\n",
    "\t#reconstruct the approximation\n",
    "\trback = sum([ np.round(reconstruction_basis[i],12)*borns_approx[i] for i in range(4**d) ])\n",
    "\t#brute force approximation upon LI\n",
    "\tcleanRho = eigenvaluesCheck(rback)\n",
    "\n",
    "\tchol_exp = [ vectorization_new(cleanRho)  ]\n",
    "\ttry:\n",
    "\t\ttotarr.append( chol_exp )\n",
    "\t\t#li2.append(fidelity(Qobj(cleanRho ),Qobj(rm[i][0])))\n",
    "\t\ti+=1\n",
    "\t\t#print(np.array(totarr).shape),print(i)\n",
    "\texcept RuntimeError:\n",
    "\t\tpass\n",
    "\t\n",
    "\tif i == tot:\n",
    "\n",
    "\t\tnp.save(folder +filename,np.array(totarr))\n",
    "\t\tbreak\n",
    "\telse:\n",
    "\t\tpass\n",
    "\t\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54bf55dae4fbbcd74478461c9a4da52328889948e2bf56774ddf4293e1ab2d69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
