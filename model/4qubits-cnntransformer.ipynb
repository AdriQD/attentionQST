{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FNZzM4LheAlY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGRiHfcTeAld"
   },
   "source": [
    "UPload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "k_vus6lkeAlh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "trials = 1000\n",
    "url = 'somefile'\n",
    "\n",
    "tomo = np.load(url, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zodin5T96rch",
    "outputId": "3c2193bc-711f-4c1f-b913-a9d8883bc60a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tomo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sN2JV_zAeAlj",
    "outputId": "28466989-dced-46cc-952b-5331ae9ce2cb",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10050, 512), (1485, 512), (3000, 512))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tomo_train, tomo_temp = train_test_split(tomo, test_size=0.33, random_state=1)\n",
    "tomo_valid,tomo_test = train_test_split(tomo_temp, test_size=0.7,random_state=1)\n",
    "\n",
    "\n",
    "import random\n",
    "valid = tomo_valid\n",
    "train = tomo_train\n",
    "test = tomo_test[:3000]\n",
    "\n",
    "random.shuffle(train)\n",
    "random.shuffle(valid)\n",
    "random.shuffle(test)\n",
    "\n",
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-P1qhXX-eAlk"
   },
   "source": [
    "##### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CeSIEWDheAlk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StatesDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index]\n",
    "\n",
    "train_dataset = StatesDataset(train)\n",
    "evaluation_dataset = StatesDataset(valid)\n",
    "\n",
    "test_dataset = StatesDataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyvYi_5neAll"
   },
   "source": [
    "# Model and seed fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "QM9CVrpjhjGo",
    "outputId": "dca31510-79e3-4a40-bd63-95f641524cc7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.empty_cache\n",
    "del(Netbeta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XL-In4pzeAln",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Netbeta(nn.Module):\n",
    "    def __init__(self, state_local_d, num_low_triang, out_channel, nheads, dim_ff ):\n",
    "        super().__init__()\n",
    "\n",
    "        kernel = 21\n",
    "        kernel2 = 21\n",
    "        \n",
    "\n",
    "        padd = 10 #modello scon convtranspose era a 24, kernel1 = 49, all strid = 1\n",
    "        strid1 = 1\n",
    "        strid2 = 1\n",
    "        model_dim = int((state_local_d + num_low_triang*2 - kernel + 2*padd)/strid1)+1\n",
    "\n",
    "\n",
    "        #ENCODING\n",
    "        self.conv1 = nn.Conv1d(1, out_channel, kernel_size = kernel, padding = padd,stride = strid1 )\n",
    "        self.conv2 = nn.Conv1d(out_channel, 1, kernel_size = kernel2, padding = padd, stride = strid2 )\n",
    "\n",
    "\n",
    "        #RECONSTRUCTION\n",
    "\n",
    "        self.enc_transf = nn.TransformerEncoderLayer(d_model = model_dim, nhead = nheads, dim_feedforward = dim_ff, batch_first = True, norm_first=True)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.enc_stack = nn.TransformerEncoder(self.enc_transf, num_layers=2)\n",
    "        self.T = torch.nn.Tanh()\n",
    "        self.G = torch.nn.GELU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #ENCODING\n",
    "\n",
    "        x = self.G(self.conv1(x)) #this for pauli's\n",
    "        #x= F.selu(self.conv1(x))\n",
    "\n",
    "        #DECODING\n",
    "\n",
    "        x= self.G(self.enc_stack(x))\n",
    "\n",
    "        x = self.T(self.conv2(x))\n",
    "        x = torch.flatten(x,1) \n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RjIGeJXeAlo"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOJrak9YeAlp"
   },
   "source": [
    "leading parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LE5Y9UR6eAlq",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f66f40655d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "local_dim = 16\n",
    "dim = 1\n",
    "torch.manual_seed(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfJbr_hLeAlq"
   },
   "source": [
    "network parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLePRBqLEqCV"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zd564H1NeAlr",
    "outputId": "0d12742d-14e7-4fb3-a37b-d48c5ae327fd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.0\n"
     ]
    }
   ],
   "source": [
    "num_killed_inputs = 0\n",
    "\n",
    "input_dim = local_dim**(2*dim)\n",
    "batch_size = 500\n",
    "\n",
    "statedim = local_dim**dim\n",
    "lowerval = (statedim**2 -statedim)/2\n",
    "print(lowerval)\n",
    "\n",
    "device = \"cuda\"\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 1000\n",
    "\n",
    "\n",
    "\n",
    "netb = Netbeta(int(local_dim) , int(lowerval), 2,1,20)\n",
    "themodelbeta  = netb.to(device)\n",
    "themodelbeta = themodelbeta.double()\n",
    "\n",
    "\n",
    "def normalization_loss(inp):\n",
    "\n",
    "  batchsize = inp.shape[0]\n",
    "\n",
    "  #return torch.abs(torch.sum(torch.norm(single_vector, p ='fro', dim=1))/batchsize -1 )\n",
    "  return  torch.mean(torch.norm(inp, p ='fro', dim=1))/batchsize\n",
    "\n",
    "def diceCost(inp,target):\n",
    "    \n",
    "    a = torch.sum(torch.mul(inp,target),1)\n",
    "    b = torch.sum(torch.mul(inp,inp),1)\n",
    "    c = torch.sum(torch.mul(target,target),1)\n",
    "\n",
    "    return 1-  torch.mean(torch.div(2*a, (b+c) ))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "N811svmUeAlr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    evaluation_dataset, batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "sGL-f7NkeAls",
    "outputId": "69a32451-440a-4e68-eda9-79f87c9d4b93",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "rec_loss = torch.nn.MSELoss()\n",
    "#optimizer = optim.RMSprop(themodelbeta.parameters(), lr=learning_rate)\n",
    "optimizer = optim.Rprop(themodelbeta.parameters(), lr = learning_rate, step_sizes = (1e-6,1e-4))\n",
    "\n",
    "\n",
    "val_hist = []\n",
    "train_hist = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    for inputs in train_dataloader:\n",
    "\n",
    "        themodelbeta.train()\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        #INPUTS RESHAPING\n",
    "\n",
    "        newin = torch.reshape(inputs[:,:local_dim**(2*dim)  ], (inputs.shape[0],1,local_dim**(2*dim )) )\n",
    "        target = inputs[:,local_dim**2:]\n",
    "        out = themodelbeta(newin)\n",
    "\n",
    "        loss = rec_loss(out, target) + normalization_loss(out)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    valid_loss = 0\n",
    "    for inputs in valid_dataloader:\n",
    "        with torch.no_grad():\n",
    "            themodelbeta.train()\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            target = inputs[:,local_dim**2:]\n",
    "\n",
    "\n",
    "            #INPUTS RESHAPING\n",
    "\n",
    "            newin = torch.reshape(inputs[:,:local_dim**(2*dim)  ], (inputs.shape[0],1,local_dim**(2*dim )) )\n",
    "            out = themodelbeta(newin)\n",
    "\n",
    "            loss = rec_loss(out, target) + normalization_loss(out)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "\n",
    "    print(epoch, train_loss/len(train_dataloader), valid_loss/len(valid_dataloader))\n",
    "    val_hist.append(valid_loss/len(valid_dataloader))\n",
    "    train_hist.append(train_loss/len(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSNTsFMgeAls"
   },
   "source": [
    "# Test. HS and fidelity reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7M9WfHMeAlt"
   },
   "source": [
    "## matrix reconstruction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wveIo4E73_FF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xf6_BjnneAlt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_matrix_elements(stuff,d,local_dim):\n",
    "\n",
    "\tdiag_len = local_dim**d\n",
    "\tdiagel = stuff[local_dim**(2*d) : local_dim**(2*d)  + diag_len  ]\n",
    "\toffd = stuff[ local_dim**(2*d)  + diag_len :  ]\n",
    "\treturn diagel, offd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cf8cSl7EeAlt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rebuild_last(diags,offd,ind):\n",
    "    '''''\n",
    "    input.\n",
    "    diags : diags elements\n",
    "    offds : offdiagonal elements\n",
    "    rhoshape : just the dm dimension, e.g. number of rows\n",
    "    localDim : the number of level of each particle\n",
    "    numParticles : the total number of particles for tensor product\n",
    "\n",
    "    output.\n",
    "    m : reconstructed cholesky decoposition matrix\n",
    "    '''''\n",
    "    d = len(diags)\n",
    "    eye = np.eye(d,d)\n",
    "    mat = np.zeros((d,d),dtype = complex)\n",
    "\n",
    "    offvalues = [ (a+1j*b) for (a,b) in zip(offd[:int(len(offd)/2 ) ], offd[int(len(offd)/2):])  ]\n",
    "    mat[ind[0], ind[1]] = offvalues\n",
    "\n",
    "    return mat + eye*diags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqRPvuzneAlu"
   },
   "source": [
    "## test stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXsfNYk6eAlu",
    "outputId": "3c5cacd6-104a-45c9-ccb9-3b9251fc9a57",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amacarone/miniconda3/envs/cudaml2/lib/python3.11/site-packages/qutip/__init__.py:96: UserWarning: matplotlib not found: Graphics will not work.\n",
      "  warnings.warn(\"matplotlib not found: Graphics will not work.\")\n"
     ]
    }
   ],
   "source": [
    "#just generate ones the index for the recosntruction using a dull matrix\n",
    "\n",
    "import qutip as qt\n",
    "def fid(a,b):\n",
    "  fid = qt.fidelity(qt.Qobj(a), qt.Qobj(b))\n",
    "  return torch.tensor(fid)\n",
    "\n",
    "\n",
    "#parameters\n",
    "qfid =0\n",
    "j=0\n",
    "hs = []\n",
    "fids =[]\n",
    "\n",
    "# generate support diagonal matrix for reconstruction\n",
    "e = np.eye(local_dim**(dim),local_dim**(dim))\n",
    "print(e.shape)\n",
    "\n",
    "#indeces for the reconstruction function\n",
    "ind = np.tril_indices_from(e,k=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vVueaI9jIEs6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bruteForce(dm):\n",
    "\n",
    "\teis, eigvecs = np.linalg.eig(dm)\n",
    "\n",
    "\teis[eis <0 ] = 0.00001\n",
    "\teis = [ el.real for el in eis]\n",
    "\teis = np.array(eis)/sum(eis)\n",
    "\n",
    "\tcleanRho = eigvecs@ np.diag(eis) @ eigvecs.T.conj()\n",
    "\n",
    "\treturn cleanRho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuFJ2SCPeAlu",
    "outputId": "36698142-7474-4f50-ed48-9027f2f261a6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averaged quantum fidelity  0.6113 \n",
      "0.13399513\n",
      "hilbert schmidt distance average  0.7281\n",
      "hilbert schmidt distance std  0.2522\n"
     ]
    }
   ],
   "source": [
    "file_ = []\n",
    "originals = []\n",
    "with torch.no_grad():\n",
    "  for inputs in test_dataloader:\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    #out_d is the diagonal, out_tr the triangluar values, real and complex altogether\n",
    "    newin = torch.reshape(inputs[:,:local_dim**(2*dim) ], (inputs.shape[0],1,local_dim**2) )\n",
    "\n",
    "    out = themodelbeta(newin)\n",
    "\n",
    "    for i in range(out.shape[0]):\n",
    "\n",
    "      #reconstructing cholesky from dataset input array. NO MORE NEEDED\n",
    "      diagel, offd = return_matrix_elements( inputs[i].cpu().numpy(), dim, local_dim)\n",
    "\n",
    "      original_chol = rebuild_last(diagel, offd , ind)\n",
    "\n",
    "      #reconstructing cholesky from neural network outputs\n",
    "\n",
    "      nn_out = out[i].cpu().numpy()\n",
    "      nn_diag = nn_out[:local_dim]\n",
    "      nn_offd = nn_out[local_dim: local_dim**2]\n",
    "\n",
    "      nn_chol = rebuild_last(nn_diag, nn_offd, ind)\n",
    "\n",
    "      cholo=nn_chol@ nn_chol.conj().T\n",
    "      norm = np.trace(cholo)\n",
    "\n",
    "\n",
    "      #fidelity between reconstructed and originals\n",
    "\n",
    "      fids.append(fid(original_chol@ original_chol.conj().T,cholo/norm) )\n",
    "      hs.append(qt.hilbert_dist(qt.Qobj(cholo/norm), qt.Qobj(original_chol@ original_chol.conj().T)))\n",
    "\n",
    "      file_.append(cholo/norm)\n",
    "      originals.append(original_chol@ original_chol.conj().T)\n",
    "\n",
    "print(f\"averaged quantum fidelity {np.mean(fids): .4f} \")#dont forget the j to divide by\n",
    "\n",
    "print(np.std(fids))\n",
    "print(f\"hilbert schmidt distance average {np.mean(hs): .4f}\")\n",
    "print(f\"hilbert schmidt distance std {np.std(hs): .4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gO0qPFBnSrdW"
   },
   "source": [
    "## file saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "zG5RtFOG0fpP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(themodelbeta, 'modelsHAAR4qubits'+str(trials)+'-FID97Pauli.pth' )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
