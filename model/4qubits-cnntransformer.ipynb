{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FNZzM4LheAlY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import qutip as qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGRiHfcTeAld"
   },
   "source": [
    "UPload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "k_vus6lkeAlh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "url = 'somefile'\n",
    "tomo = np.load(url, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zodin5T96rch",
    "outputId": "3c2193bc-711f-4c1f-b913-a9d8883bc60a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tomo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sN2JV_zAeAlj",
    "outputId": "28466989-dced-46cc-952b-5331ae9ce2cb",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10050, 512), (1485, 512), (3000, 512))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tomo_train, tomo_temp = train_test_split(tomo, test_size=0.33, random_state=1)\n",
    "tomo_valid,tomo_test = train_test_split(tomo_temp, test_size=0.7,random_state=1)\n",
    "\n",
    "\n",
    "import random\n",
    "valid = tomo_valid\n",
    "train = tomo_train\n",
    "test = tomo_test \n",
    "\n",
    "random.shuffle(train)\n",
    "random.shuffle(valid)\n",
    "random.shuffle(test)\n",
    "\n",
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-P1qhXX-eAlk"
   },
   "source": [
    "##### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CeSIEWDheAlk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StatesDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index]\n",
    "\n",
    "\n",
    "train_dataset = StatesDataset(train)\n",
    "evaluation_dataset = StatesDataset(valid)\n",
    "test_dataset = StatesDataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyvYi_5neAll"
   },
   "source": [
    "# Model and seed fixing\n",
    "\n",
    "- for the 4 qubits model, Haar states, the network hyper parameters were set as: \n",
    "    - kernel(s) =21\n",
    "    - padd = 10\n",
    "    - stride =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XL-In4pzeAln",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Netbeta(nn.Module):\n",
    "    def __init__(self, state_local_d, num_low_triang, out_channel, nheads, dim_ff ):\n",
    "        super().__init__()\n",
    "\n",
    "        kernel = 21\n",
    "        kernel2 = 21\n",
    "        \n",
    "\n",
    "        padd = 10 #modello scon convtranspose era a 24, kernel1 = 49, all strid = 1\n",
    "        strid1 = 1\n",
    "        strid2 = 1\n",
    "        model_dim = int((state_local_d + num_low_triang*2 - kernel + 2*padd)/strid1)+1\n",
    "\n",
    "\n",
    "        #ENCODING\n",
    "        self.conv1 = nn.Conv1d(1, out_channel, kernel_size = kernel, padding = padd,stride = strid1 )\n",
    "        self.conv2 = nn.Conv1d(out_channel, 1, kernel_size = kernel2, padding = padd, stride = strid2 )\n",
    "\n",
    "\n",
    "        #RECONSTRUCTION\n",
    "\n",
    "        self.enc_transf = nn.TransformerEncoderLayer(d_model = model_dim, nhead = nheads, dim_feedforward = dim_ff, batch_first = True, norm_first=True)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.enc_stack = nn.TransformerEncoder(self.enc_transf, num_layers=2)\n",
    "        self.T = torch.nn.Tanh()\n",
    "        self.G = torch.nn.GELU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #ENCODING\n",
    "\n",
    "        x = self.G(self.conv1(x)) #this for pauli's\n",
    "        #x= F.selu(self.conv1(x))\n",
    "\n",
    "        #DECODING\n",
    "\n",
    "        x= self.G(self.enc_stack(x))\n",
    "\n",
    "        x = self.T(self.conv2(x))\n",
    "        x = torch.flatten(x,1) \n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RjIGeJXeAlo"
   },
   "source": [
    "# Training\n",
    "\n",
    "the total dimension of the Hilber Schmidt space is given by ${\\rm localdim}^{\\times dim}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LE5Y9UR6eAlq",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f66f40655d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "local_dim = 16\n",
    "dim = 1\n",
    "torch.manual_seed(13) # seed fixing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfJbr_hLeAlq"
   },
   "source": [
    "## network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zd564H1NeAlr",
    "outputId": "0d12742d-14e7-4fb3-a37b-d48c5ae327fd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.0\n"
     ]
    }
   ],
   "source": [
    "num_killed_inputs = 0\n",
    "\n",
    "input_dim = local_dim**(2*dim)\n",
    "batch_size = 1500\n",
    "\n",
    "statedim = local_dim**dim\n",
    "lowerval = (statedim**2 -statedim)/2\n",
    "print(lowerval)\n",
    "\n",
    "device = \"cuda\" \n",
    "learning_rate = 0.0001\n",
    "num_epochs = 1000\n",
    "\n",
    "netb = Netbeta(int(local_dim) , int(lowerval), 2,1,20)\n",
    "themodelbeta  = netb.to(device)\n",
    "themodelbeta = themodelbeta.double()\n",
    "\n",
    "\n",
    "def normalization_loss(inp):\n",
    "\n",
    "  \"\"\"\n",
    "  input.\n",
    "  inp = network outputs, the vectorized Cholesky.\n",
    "\n",
    "  output.\n",
    "\n",
    "  averaged Tr(CC)\n",
    "  \"\"\"\n",
    "\n",
    "  batchsize = inp.shape[0]\n",
    "\n",
    "  #return torch.abs(torch.sum(torch.norm(single_vector, p ='fro', dim=1))/batchsize -1 )\n",
    "  return  torch.mean(torch.norm(inp, p ='fro', dim=1))/batchsize\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "N811svmUeAlr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    evaluation_dataset, batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "sGL-f7NkeAls",
    "outputId": "69a32451-440a-4e68-eda9-79f87c9d4b93",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "rec_loss = torch.nn.MSELoss()\n",
    "optimizer = optim.RMSprop(themodelbeta.parameters(), lr=learning_rate)\n",
    "#optimizer = optim.Rprop(themodelbeta.parameters(), lr = learning_rate, step_sizes = (1e-6,1e-4))\n",
    "\n",
    "val_hist = []\n",
    "train_hist = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    for inputs in train_dataloader:\n",
    "\n",
    "        themodelbeta.train()\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        #INPUTS RESHAPING\n",
    "\n",
    "        newin = torch.reshape(inputs[:,:local_dim**(2*dim)  ], (inputs.shape[0],1,local_dim**(2*dim )) )\n",
    "        target = inputs[:,local_dim**2:]\n",
    "        out = themodelbeta(newin)\n",
    "\n",
    "        loss = rec_loss(out, target) + normalization_loss(out)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    valid_loss = 0\n",
    "    for inputs in valid_dataloader:\n",
    "        with torch.no_grad():\n",
    "            themodelbeta.train()\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            target = inputs[:,local_dim**2:]\n",
    "\n",
    "\n",
    "            #INPUTS RESHAPING\n",
    "\n",
    "            newin = torch.reshape(inputs[:,:local_dim**(2*dim)  ], (inputs.shape[0],1,local_dim**(2*dim )) )\n",
    "            out = themodelbeta(newin)\n",
    "\n",
    "            loss = rec_loss(out, target) + normalization_loss(out)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "\n",
    "    print(epoch, train_loss/len(train_dataloader), valid_loss/len(valid_dataloader))\n",
    "    val_hist.append(valid_loss/len(valid_dataloader))\n",
    "    train_hist.append(train_loss/len(train_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSNTsFMgeAls"
   },
   "source": [
    "# Test. HS and fidelity reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7M9WfHMeAlt"
   },
   "source": [
    "## matrix reconstruction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xf6_BjnneAlt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_matrix_elements(stuff,d,local_dim):\n",
    "\n",
    "\tdiag_len = local_dim**d\n",
    "\tdiagel = stuff[local_dim**(2*d) : local_dim**(2*d)  + diag_len  ]\n",
    "\toffd = stuff[ local_dim**(2*d)  + diag_len :  ]\n",
    "\treturn diagel, offd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cf8cSl7EeAlt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rebuild_last(diags,offd,ind):\n",
    "    '''''\n",
    "    input.\n",
    "    diags : diags elements\n",
    "    offds : offdiagonal elements\n",
    "    rhoshape : just the dm dimension, e.g. number of rows\n",
    "    localDim : the number of level of each particle\n",
    "    numParticles : the total number of particles for tensor product\n",
    "\n",
    "    output.\n",
    "    m : reconstructed cholesky decoposition matrix\n",
    "    '''''\n",
    "    d = len(diags)\n",
    "    eye = np.eye(d,d)\n",
    "    mat = np.zeros((d,d),dtype = complex)\n",
    "\n",
    "    offvalues = [ (a+1j*b) for (a,b) in zip(offd[:int(len(offd)/2 ) ], offd[int(len(offd)/2):])  ]\n",
    "    mat[ind[0], ind[1]] = offvalues\n",
    "\n",
    "    return mat + eye*diags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqRPvuzneAlu"
   },
   "source": [
    "## network testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXsfNYk6eAlu",
    "outputId": "3c5cacd6-104a-45c9-ccb9-3b9251fc9a57",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amacarone/miniconda3/envs/cudaml2/lib/python3.11/site-packages/qutip/__init__.py:96: UserWarning: matplotlib not found: Graphics will not work.\n",
      "  warnings.warn(\"matplotlib not found: Graphics will not work.\")\n"
     ]
    }
   ],
   "source": [
    "#just generate ones the index for the recosntruction using a dull matrix\n",
    "\n",
    "def fid(a,b):\n",
    "  fid = qt.fidelity(qt.Qobj(a), qt.Qobj(b))\n",
    "  return torch.tensor(fid)\n",
    "\n",
    "\n",
    "#parameters\n",
    "qfid =0\n",
    "j=0\n",
    "hs = []\n",
    "fids =[]\n",
    "\n",
    "# generate support diagonal matrix for reconstruction\n",
    "e = np.eye(local_dim**(dim),local_dim**(dim))\n",
    "print(e.shape)\n",
    "\n",
    "#indeces for the reconstruction function\n",
    "ind = np.tril_indices_from(e,k=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vVueaI9jIEs6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bruteForce(dm):\n",
    "\n",
    "\teis, eigvecs = np.linalg.eig(dm)\n",
    "\n",
    "\teis[eis <0 ] = 0.00001\n",
    "\teis = [ el.real for el in eis]\n",
    "\teis = np.array(eis)/sum(eis)\n",
    "\n",
    "\tcleanRho = eigvecs@ np.diag(eis) @ eigvecs.T.conj()\n",
    "\n",
    "\treturn cleanRho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuFJ2SCPeAlu",
    "outputId": "36698142-7474-4f50-ed48-9027f2f261a6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_ = []\n",
    "originals = []\n",
    "with torch.no_grad():\n",
    "  for inputs in test_dataloader:\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    #out_d is the diagonal, out_tr the triangluar values, real and complex altogether\n",
    "    newin = torch.reshape(inputs[:,:local_dim**(2*dim) ], (inputs.shape[0],1,local_dim**2) )\n",
    "\n",
    "    out = themodelbeta(newin)\n",
    "\n",
    "    for i in range(out.shape[0]):\n",
    "\n",
    "      #reconstructing cholesky from dataset input array. NO MORE NEEDED\n",
    "      diagel, offd = return_matrix_elements( inputs[i].cpu().numpy(), dim, local_dim)\n",
    "\n",
    "      original_chol = rebuild_last(diagel, offd , ind)\n",
    "\n",
    "      #reconstructing cholesky from neural network outputs\n",
    "\n",
    "      nn_out = out[i].cpu().numpy()\n",
    "      nn_diag = nn_out[:local_dim]\n",
    "      nn_offd = nn_out[local_dim: local_dim**2]\n",
    "\n",
    "      nn_chol = rebuild_last(nn_diag, nn_offd, ind)\n",
    "\n",
    "      cholo=nn_chol@ nn_chol.conj().T\n",
    "      norm = np.trace(cholo)\n",
    "\n",
    "\n",
    "      #fidelity between reconstructed and originals\n",
    "\n",
    "      fids.append(fid(original_chol@ original_chol.conj().T,cholo/norm) )\n",
    "      hs.append(qt.hilbert_dist(qt.Qobj(cholo/norm), qt.Qobj(original_chol@ original_chol.conj().T)))\n",
    "\n",
    "      file_.append(cholo/norm)\n",
    "      originals.append(original_chol@ original_chol.conj().T)\n",
    "\n",
    "print(f\"averaged quantum fidelity {np.mean(fids): .4f} \")#dont forget the j to divide by\n",
    "\n",
    "print(np.std(fids))\n",
    "print(f\"hilbert schmidt distance average {np.mean(hs): .4f}\")\n",
    "print(f\"hilbert schmidt distance std {np.std(hs): .4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gO0qPFBnSrdW"
   },
   "source": [
    "## file saving, model delating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "zG5RtFOG0fpP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "trials = 1\n",
    "\n",
    "torch.save(themodelbeta, 'modelsHAAR4qubits'+str(trials)+'-FID97Pauli.pth' )\n",
    "torch.cuda.empty_cache\n",
    "del(Netbeta)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
