{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import *\n",
    "import functools as fu\n",
    "from numpy import kron\n",
    "from numpy.linalg import cholesky, eig\n",
    "import torch\n",
    "\n",
    "from scipy.stats import norm\n",
    "from qiskit.quantum_info import random_density_matrix\n",
    "from qutip import rand_dm_hs, Qobj, fidelity\n",
    "\n",
    "from support_functions import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leading dimension to set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 4\n",
    "local_dim = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generating the projectors. Sic and tetra povm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basis and reconstruction basis generation. I'm currenntly focusing on the tetra only"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bornvalues"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## depolarization and dephasing channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_depolarizing_channel(qubits_number, density_matrix, probability):\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tNOTE: this function must be used inside a for loop to get to apply each pauli's operator for each state\n",
    "\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tpX = np.array([[0.,1.], [1.,0.]]) # X Pauli matrix\n",
    "\t\tpY = np.array([[0.,-1.j], [1.j, 0.]]) # Y Pauli matrix\n",
    "\t\tpZ = np.array([[1., 0.], [0.,-1.]]) # Z Pauli matrix\n",
    "\t\tpI = np.array([[1.,0.], [0.,1.]])\n",
    "\n",
    "\t\tfor i in range(qubits_number):\n",
    "\t\t\t\n",
    "\t\t\toperator_string_x = list(repeat(pI,qubits_number))\n",
    "\t\t\toperator_string_y = list(repeat(pI,qubits_number))\n",
    "\t\t\toperator_string_z = list(repeat(pI,qubits_number))\n",
    "\t\t\t\n",
    "\n",
    "\t\t\toperator_string_x[i] = pX\n",
    "\t\t\toperator_string_y[i] = pY\n",
    "\t\t\toperator_string_z[i] = pZ\n",
    "\t\n",
    "\t\t\tX = fu.reduce(np.kron,operator_string_x)\n",
    "\t\t\tY = fu.reduce(np.kron,operator_string_y)\n",
    "\t\t\tZ = fu.reduce(np.kron,operator_string_z)\n",
    "\t\t\n",
    "\t\t\tnew_density_matrix = (1-probability)*density_matrix \n",
    "\t\t\t\n",
    "\t\t\tnew_density_matrix = new_density_matrix + (probability/3)*X.dot(density_matrix).dot(X)\n",
    "\t\t\t#print(new_density_matrix.shape)\n",
    "\t\t\tnew_density_matrix = new_density_matrix + (probability/3)*Y.dot(density_matrix).dot(Y)\n",
    "\n",
    "\t\t\tnew_density_matrix = new_density_matrix + (probability/3)*Z.dot(density_matrix).dot(Z)\n",
    "\t\t\t\t\n",
    "\t\treturn new_density_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_depo_channel(dm,p):\n",
    "    \n",
    "    dim = dm.shape[0]\n",
    "    I = np.eye(dim,dim)\n",
    "    \n",
    "    return (1-p)*dm + (p/(dim))*I\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "producing data files. Separable and entangled as usual\n",
    "Cholesky decomposition included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vectorization_new(rho):\n",
    "\t\n",
    "\tdim = rho.shape[0]\n",
    "\t#chol = np.linalg.cholesky(rho)\n",
    "\tchol = \ttorch.linalg.cholesky(torch.complex(torch.Tensor(rho.real),torch.Tensor(rho.imag)))\n",
    "\n",
    "\tdiag = np.diag(chol).real.tolist()\n",
    "\n",
    "\tlower_t_indeces = np.tril_indices_from(chol,k=-1)\n",
    "\n",
    "\treals = list(chol[lower_t_indeces].real.flatten())\n",
    "\timags = list(chol[lower_t_indeces].imag.flatten())\n",
    "\n",
    "\treturn np.array(diag+reals+imags, dtype=np.float64)\n",
    "\n",
    "def vectorization_noChol(rh):\n",
    "\n",
    "\tdiag = np.diag(rh).real.tolist()\n",
    "\tlower_t_indeces = np.tril_indices_from(rh,k=-1)\n",
    "\n",
    "\treals = list(rh[lower_t_indeces].real.flatten())\n",
    "\timags = list(rh[lower_t_indeces].imag.flatten())\n",
    "\n",
    "\treturn np.array(diag+reals+imags, dtype=np.float64)\n",
    "\n",
    "\n",
    "def from_mpc_tonumpy(colored_rho):\n",
    "\n",
    "\t\"\"\"\n",
    "\tinput: a density matrix, mpc type\n",
    "\toutput: nd.array of the same density matrix recasted in complex128 type\n",
    "\t\"\"\"\n",
    "\tplaceholder = np.zeros((colored_rho.shape[0],colored_rho.shape[1]),dtype=complex)\n",
    "\tfor r in range(colored_rho.shape[0]):\n",
    "\t\tfor c in range(colored_rho.shape[1]):\n",
    "\t\t\ta =np.double(mp.nstr(mp.re(colored_rho[r][c])))\n",
    "\t\t\tb = np.double(mp.nstr(mp.im(colored_rho[r][c])))\n",
    "\t\t\tbuilt = complex(a,b)\n",
    "\t\t\tplaceholder[r][c] = built\n",
    "\treturn placeholder\n",
    "\n",
    "def eigenvaluesCheck(dm):\n",
    "\n",
    "\teis, eigvecs = eig(dm)\n",
    "\n",
    "\teis[eis.real <0 ] = 0.0001\n",
    "\teis = [ el.real for el in eis]\n",
    "\teis = np.array(eis)\n",
    "\n",
    "\tcleanRho = eigvecs@ np.diag(eis) @ eigvecs.T.conj()\n",
    "\n",
    "\treturn cleanRho/np.trace(cleanRho)\n",
    "\t\n",
    "def PureEigenvaluesCheck(dm):\n",
    "\n",
    "\teis, eigvecs = eig(dm)\n",
    "\n",
    "\teis[eis.real.round(2) < 0.99 ] = 0.0001\n",
    "\teis = [ el.real for el in eis]\n",
    "\teis = np.array(eis)\n",
    "\n",
    "\tcleanRho = eigvecs@ np.diag(eis) @ eigvecs.T.conj()\n",
    "\n",
    "\treturn cleanRho/np.trace(cleanRho)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the n qubits basis\n",
    "\n",
    "one to generate the frequencies, the dual to reconstruct a density matrix out of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "general_basis = np.load(\"../4qubitsPauli.npy \", allow_pickle=True)\n",
    "reconstruction_basis = np.load(\"../4qubitsPauliReconstruction.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_basis.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAULI basis data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.stats import norm\n",
    "\n",
    "totarr =[]\n",
    "hs = []\n",
    "tot =1\n",
    "i = 0\n",
    "li = []\n",
    "\n",
    "trials = 1000\n",
    "\n",
    "normTrials = np.sqrt(trials/(local_dim**(d)))\n",
    "\n",
    "folder = '../multinomialData/'\n",
    "filename = 'Haar4qubitsTrials'+str(trials)+'PAULI.npy'\n",
    "\n",
    "if not os.path.isdir(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "def HSdist(A,B):\n",
    "    return np.trace((A-B)@(A-B)).real\n",
    "  \n",
    "hsm = []\n",
    "while True:\n",
    "\n",
    "\t#PURE STATES\n",
    "\trho_start0 = np.array(random_density_matrix(local_dim**d,rank=1, method = \"Hillbert_Schmidt\").data)\n",
    "\t#rho_start0 = global_depo_channel(rho_start0,0.1)\n",
    "\tborns =  np.array([ np.trace(rho_start0 @ base).real for base in general_basis])\n",
    "\n",
    "\t#OLD ONE\n",
    "\tsingleFreqVariance = norm.rvs(size = local_dim**(2*d))/18\n",
    "\t#\n",
    "\tborns_approx =  [ el1+el2 for el1,el2 in zip(borns,singleFreqVariance) ]  \n",
    "\n",
    "\t#reconstruct the approximation\n",
    "\trback = sum([ np.round(reconstruction_basis[i],12)*borns_approx[i] for i in range(4**d) ])\n",
    "\t\n",
    "\t#brute force approximation upon LI\n",
    "\tcleanRho = eigenvaluesCheck(rback)\n",
    "\n",
    "\tchol_exp = [ vectorization_new(cleanRho)  ]\n",
    "\n",
    "\ttry:\n",
    "\t\t#LI test\n",
    "\t\tli.append(fidelity(Qobj(cleanRho),Qobj(rho_start0)))\n",
    "\t\t#hs.append(HSdist(cleanRho,rho_start0 ))\n",
    "\n",
    "\t\tchol_theoretic = vectorization_new(PureEigenvaluesCheck(rho_start0))\n",
    "\t\ttotarr.append( np.concatenate((chol_exp, chol_theoretic), axis=None) )\n",
    "\t\ti+=1\n",
    "\t\t#print(i)\n",
    "\texcept RuntimeError:\n",
    "\t\tpass\n",
    "\t\n",
    "\tif i == tot:\n",
    "\n",
    "\t\t#np.save(folder +filename,np.array(totarr))\n",
    "\t\tbreak\n",
    "\telse:\n",
    "\t\tpass\n",
    "\t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUT OF DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rm = pd.read_pickle('outofdistribution100.pkl').to_numpy()\n",
    "\n",
    "rm[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "measurement_error =  norm.rvs(size = local_dim**(2*d))/25\n",
    "print(np.mean(measurement_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.stats import norm\n",
    "\n",
    "totarr =[]\n",
    "tot = rm.shape[0]\n",
    "i = 0\n",
    "li2 = []\n",
    "#trials = 1000\n",
    "#normTrials = np.sqrt(trials/(local_dim**(d)))\n",
    "\n",
    "trials = 100000\n",
    "#filename = 'sample11-100stepsPauli4qubitsTrials'+str(trials)+'OfD.npy'\n",
    "filename = 'sample2B-OATPauli85Depo0.3andMeasurementError.npy'\n",
    "\n",
    "\n",
    "hsm = []\n",
    "while True:\n",
    "\t\n",
    "\trmdepo = global_depo_channel(rm[i][0],0.3)\n",
    "\tprint(np.trace(rmdepo@rmdepo))\n",
    "\tborns =  np.array([ np.trace(rmdepo @ base).real for base in general_basis])\n",
    "\n",
    "\n",
    "\t#borns_approx = np.random.multinomial(trials, borns)/trials\n",
    "\n",
    "\t#FOR PAULIS plus error measurement\n",
    "\tsingleFreqVariance = norm.rvs(size = local_dim**(2*d))/18 + measurement_error\n",
    "\t#FOR PAULIs\n",
    "\t#singleFreqVariance = norm.rvs(size = local_dim**(2*d))/18\n",
    "\t#\n",
    "\tborns_approx =  [ el1+el2 for el1,el2 in zip(borns,singleFreqVariance) ]  \n",
    "\n",
    "\t#reconstruct the approximation\n",
    "\trback = sum([ np.round(reconstruction_basis[i],12)*borns_approx[i] for i in range(4**d) ])\n",
    "\t#brute force approximation upon LI\n",
    "\tcleanRho = eigenvaluesCheck(rback)\n",
    "\n",
    "\tchol_exp = [ vectorization_new(cleanRho)  ]\n",
    "\ttry:\n",
    "\t\ttotarr.append( chol_exp )\n",
    "\t\t#totarr.append( rback )\n",
    "\t\tli2.append(fidelity(Qobj(cleanRho ),Qobj(rm[i][0])))\n",
    "\t\ti+=1\n",
    "\t\t#print(np.array(totarr).shape),print(i)\n",
    "\texcept RuntimeError:\n",
    "\t\tpass\n",
    "\t\n",
    "\tif i == tot:\n",
    "\n",
    "\t\tnp.save('forPRR/'+filename,np.array(totarr))\n",
    "\t\tbreak\n",
    "\telse:\n",
    "\t\tpass\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(li2), np.std(li2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54bf55dae4fbbcd74478461c9a4da52328889948e2bf56774ddf4293e1ab2d69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
